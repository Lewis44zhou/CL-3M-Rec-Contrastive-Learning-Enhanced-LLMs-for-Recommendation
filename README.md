# CL^3M-Rec-Contrastive-Learning-Enhanced-LLMs-for-Recommendation

This repository contains the source code for **CL3M-Rec**, a framework that enhances Large Language Models (LLMs) with contrastive learning for recommendation tasks.

## ğŸ“¦ Download Large Files
Due to GitHubâ€™s file size limits, large files (e.g., datasets, pre-trained models, processed data) are hosted on Google Drive:

ğŸ‘‰ [Google Drive Folder](https://drive.google.com/drive/folders/1dfe2gw2L1ltcK0ogbGejtueFGDJG24cO?dmr=1&ec=wgc-drive-hero-goto)

Please download the files and follow this guideline to run the codeã€‚
---

## âš™ï¸ Getting Started

### 1. Download the files
Download from Google Drive (link provided above).

### 2. Set up the environment
```bash
conda env create -f environment.yml
conda activate cl3mrec
```

### 3. Code Structure
```bash
â”œâ”€â”€ .git/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Git repository metadata
â”‚
â”œâ”€â”€ collm-datasets/Â  Â  Â  Â  Â  Â  Â  Â # Raw and processed datasets for CoLLM-Rec
â”œâ”€â”€ dataset/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Dataset preprocessing scripts
â”œâ”€â”€ figs/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Figures used in paper/README
â”‚
â”œâ”€â”€ minigpt4/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Core code of CLÂ³M-Rec (built on MiniGPT-4)
â”‚Â  Â â”œâ”€â”€ models/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Model architectures (CoLLM, LGCN, MF, SASRec)
â”‚Â  Â â”œâ”€â”€ datasets/Â  Â  Â  Â  Â  Â  Â  Â  Â # Dataset classes and dataloaders
â”‚Â  Â â”œâ”€â”€ task/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Task definitions (training/evaluation workflows)
â”‚Â  Â â”œâ”€â”€ runners/Â  Â  Â  Â  Â  Â  Â  Â  Â  # Runner for managing training and evaluation
â”‚Â  Â â”œâ”€â”€ common/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Utility functions (logging, metrics, helpers)
â”‚Â  Â â”œâ”€â”€ configs/Â  Â  Â  Â  Â  Â  Â  Â  Â  # Model & experiment configurations
â”‚Â  Â â””â”€â”€ __init__.pyÂ  Â  Â  Â  Â  Â  Â  Â # Package initializer
â”‚
â”œâ”€â”€ minigpt4rec-log/Â  Â  Â  Â  Â  Â  Â  # Training and evaluation logs (tensorboard, checkpoints)
â”œâ”€â”€ train_configs/Â  Â  Â  Â  Â  Â  Â  Â  # Training configs (YAML files for hyperparameters)
â”‚
â”œâ”€â”€ baseline_train_lightgcn_ood.pyÂ  Â  Â  Â  # Baseline training: LightGCN (out-of-domain)
â”œâ”€â”€ baseline_train_lightgcn_ood_amazon.py # Baseline training: LightGCN (Amazon dataset OOD)
â”œâ”€â”€ baseline_train_mf_ood.pyÂ  Â  Â  Â  Â  Â  Â  # Baseline training: Matrix Factorization (OOD)
â”œâ”€â”€ baseline_train_mf_ood_amazon.pyÂ  Â  Â  Â # Baseline training: Matrix Factorization (Amazon OOD)
â”œâ”€â”€ baseline_train_sasrec.pyÂ  Â  Â  Â  Â  Â  Â  # Baseline training: SASRec
â”œâ”€â”€ baseline_train_sasrec_amazon.pyÂ  Â  Â  Â # Baseline training: SASRec (Amazon dataset)
â”‚
â”œâ”€â”€ environment.ymlÂ  Â  Â  Â  Â  Â  Â  Â # Conda environment configuration
â”œâ”€â”€ train_cl_llm_rec.pyÂ  Â  Â  Â  Â  Â # Main training script for the CLÂ³M-Rec model
â”œâ”€â”€ run_test.pyÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â # Script to run evaluation on test sets
â”œâ”€â”€ LICENSEÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # License file for the repository
â”œâ”€â”€ README_minigpt4.mdÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Main documentation file
â””â”€â”€ requirements.txtÂ  Â  Â  Â  Â  Â  Â  # Python package requirements
â”œâ”€â”€ train_collm_lgcn.py       # Training with LGCN backbone
â”œâ”€â”€ test.json
â”œâ”€â”€ train_collm_lgcn.py       # Training with LGCN backbone
â”œâ”€â”€ train_collm_mf_din.py     # Training with MF + DIN backbone
â”œâ”€â”€ train_collm_sasrec.py     # Training with SASRec backbone
```

### 4. ğŸš€ Training

The main training entry point is:

```bash
python train_cl_llm_rec.py --config ./train_configs/config.yaml
```

Each config file controls LoRA/CIE tuning stages, datasets, and evaluation metrics. Please adjust them as needed.

### ğŸ™Œ Acknowledgements
Our implementation builds upon the structure of MiniGPT-4. We thank the open-source community for their contributions.

```bash
This work was supported by:

Guangdong Provincial Key Laboratory of Intellectual Property and Big Data (2018B030322016)

National Key Research and Development Program of China (2024YFA1011900)

Open Project Program of Guangxi Key Laboratory of Digital Infrastructure (GXDIOP2024011)

Guangxi Key R&D Program (2024AB08144)

NSFC (62276277)
```

### ğŸ“‘ Citation
If you find this work useful in your research, please cite:
```bash
@inproceedings{zhou2025cl3mrec,
  title     = {CLÂ³M-Rec: Contrastive Learning Enhanced LLMs for Recommendation},
  author    = {Yu-Xuan Zhou and Ru-Bin Li and Zhe Xuan-Yuan and Chang-Dong Wang and Pei-Yuan Lai},
  booktitle = {Proceedings of the IEEE International Conference on Data Mining (ICDM)},
  year      = {2025}
}
```

